{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Empirical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import warnings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')\n",
    "path = os.getenv(\"ROOT_PATH\")\n",
    "sys.path.append(path)\n",
    "print(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of **all the current components** of the OMX Stockholm PI index can be found [here](https://indexes.nasdaqomx.com/Index/Weighting/OMXSPI) by the end of the day of 16th February 2024.\n",
    "\n",
    "The list of **large-caps** of the OMX Stockholm PI index can be found [here](https://indexes.nasdaqomx.com/Index/Weighting/OMXSLCPI) by the end of the day of 16th February 2024.\n",
    "\n",
    "The list of **mid-caps** of the OMX Stockholm PI index can be found [here](https://indexes.nasdaqomx.com/Index/Weighting/OMXSMCPI) by the end of the day of 16th February 2024.\n",
    "\n",
    "The list of **small-caps** of the OMS Stockholm PI index can be found [here](https://indexes.nasdaqomx.com/Index/Weighting/OMXSSCPI) by the end of the day of 16th February 2024.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following steps we're charging the name of all the components and turn them into a list.\n",
    "\n",
    "The latter will be used to fetch the data - adjusted closed price and volume - from Yahoo Finance. And save accordingly in a file called `raw_data.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers= pd.read_excel(f\"{path}/raw_data/main/Weightings_20240216_OMXSPI.xlsx\",header=0)\n",
    "# If error shows up run: !pip3 install xlrd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_list=tickers['Security-Symbol'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = yf.download(tickers_list, start=\"2014-03-06\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(f\"{path}/raw_data/raw_data.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During the following cells we are going to create different lists with the names of the companies considered large-caps, mid-caps, and small caps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_caps=pd.read_excel(f\"{path}/raw_data/main/large_caps.xlsx\")\n",
    "l_caps_list=l_caps['Security-Symbol'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_caps=pd.read_excel(f\"{path}/raw_data/main/mid_caps.xlsx\")\n",
    "m_caps_list=m_caps['Security-Symbol'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_caps=pd.read_excel(f\"{path}/raw_data/main/small_caps.xlsx\")\n",
    "s_caps_list=s_caps['Security-Symbol'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(l_caps_list)+len(m_caps_list)+len(s_caps_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tickers_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one company that we cannot classify as large, mid or small-cap. \n",
    "\n",
    "It'll be pointed out in the following steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After downloading the data in the file `raw_data.csv` you must open it in Microsoft Excel.\n",
    "In the **first row** we can find the number of the metric fetched.\n",
    "In the **second row** we can find the names of the different companies.\n",
    "In the **first column** we can find the dates we have exported.\n",
    "\n",
    "To clean up the dataset, delete those columns where the first row differs from `adjClose` and `volume`.\n",
    "As soon as this is done, cut those columns where the first row is `volume` and paste them in a new spreadsheet (not tab). \n",
    "Remove the first row as it doesn't add useful information at the moment. Call `volumes` to this new spreadsheet and save it as a .csv file.\n",
    "\n",
    "Come back to the initial spreadsheet called `raw_data.csv`. \n",
    "Since we only have `adjClose` prices, remove the first row.\n",
    "Rename the spreadsheet as `price` and save it as a .csv file\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_price = pd.read_excel(f'{path}/raw_data/main/price.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of companies in the sample: {df_price.shape[1]-2}\") # Excluding the 'Date' and '^OMXSPI' columns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_percentage_dict={'Company':[],'Null_percentage':[],'Type':[]}\n",
    "\n",
    "for column in df_price.columns[1:-1]:\n",
    "    company_name=column\n",
    "    null_percentage = df_price[company_name].isnull().mean()*100\n",
    "    null_percentage_dict['Company'].append(company_name)\n",
    "    null_percentage_dict['Null_percentage'].append(null_percentage)\n",
    "    if company_name in l_caps_list:\n",
    "        null_percentage_dict['Type'].append(\"l-cap\")\n",
    "    elif company_name in m_caps_list:\n",
    "        null_percentage_dict['Type'].append(\"m-cap\")\n",
    "    elif company_name in s_caps_list:\n",
    "        null_percentage_dict['Type'].append(\"s-cap\")\n",
    "    else: null_percentage_dict['Type'].append(\"non-registered\")\n",
    "\n",
    "df_null_percentage=pd.DataFrame.from_dict(null_percentage_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_percentage[df_null_percentage['Type']==\"non-registered\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_percentage=df_null_percentage.sort_values(by=\"Null_percentage\",ascending=False)\n",
    "\n",
    "df_null_percentage.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_null_percentage.to_excel(f'{path}/raw_data/main/null_percentage.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_null_percentage, x='Company', y='Null_percentage', color='Type',\n",
    "             labels={'Null_percentage': 'Null_percentage'},\n",
    "             title='Null Percentage of Companies by Cap Classification',\n",
    "             hover_data=['Company', 'Null_percentage', 'Type'])\n",
    "fig.update_layout(barmode='group', xaxis_title='Company', yaxis_title='Null_percentage')\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Components over time of the OMXSPI [here](https://indexes.nasdaqomx.com/Index/Weighting/OMXSPI)\n",
    "\n",
    "Methodology of the index [here](https://indexes.nasdaqomx.com/docs/Methodology_Nordic_AllShare.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proxy A:\n",
    "\n",
    "Daily raw stock returns with absolute values exceeding 8% and 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_8_percent_large = 0.08\n",
    "threshold_10_percent_large = 0.10\n",
    "\n",
    "threshold_10_percent_mid = 0.10\n",
    "threshold_12_percent_mid = 0.12\n",
    "\n",
    "threshold_12_percent_small = 0.13\n",
    "threshold_14_percent_small =  0.15\n",
    "\n",
    "proxy_a_df = pd.DataFrame(df_price['Date'].copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in l_caps_list:\n",
    "    stock_returns = df_price[column].pct_change()\n",
    "\n",
    "    # Create proxy columns based on the defined thresholds for large-caps\n",
    "    proxy_a_df[f'{column}_Increase_small_thres'] = (stock_returns > threshold_8_percent_large).astype(int)\n",
    "    proxy_a_df[f'{column}_Decrease_small_thres'] = (stock_returns < -threshold_8_percent_large).astype(int)\n",
    "    proxy_a_df[f'{column}_Increase_large_thres'] = (stock_returns > threshold_10_percent_large).astype(int)\n",
    "    proxy_a_df[f'{column}_Decrease_large_thres'] = (stock_returns < -threshold_10_percent_large).astype(int)\n",
    "\n",
    "for column in m_caps_list:\n",
    "    stock_returns = df_price[column].pct_change()\n",
    "\n",
    "    # Create proxy columns based on the defined thresholds for mid-caps\n",
    "    proxy_a_df[f'{column}_Increase_small_thres'] = (stock_returns > threshold_10_percent_mid).astype(int)\n",
    "    proxy_a_df[f'{column}_Decrease_small_thres'] = (stock_returns < -threshold_10_percent_mid).astype(int)\n",
    "    proxy_a_df[f'{column}_Increase_large_thres'] = (stock_returns > threshold_12_percent_mid).astype(int)\n",
    "    proxy_a_df[f'{column}_Decrease_large_thres'] = (stock_returns < -threshold_12_percent_mid).astype(int)\n",
    "\n",
    "for column in s_caps_list:\n",
    "    stock_returns = df_price[column].pct_change()\n",
    "\n",
    "    # Create proxy columns based on the defined thresholds for small-caps\n",
    "    proxy_a_df[f'{column}_Increase_small_thres'] = (stock_returns > threshold_12_percent_small).astype(int)\n",
    "    proxy_a_df[f'{column}_Decrease_small_thres'] = (stock_returns < -threshold_12_percent_small).astype(int)\n",
    "    proxy_a_df[f'{column}_Increase_large_thres'] = (stock_returns > threshold_14_percent_small).astype(int)\n",
    "    proxy_a_df[f'{column}_Decrease_large_thres'] = (stock_returns < -threshold_14_percent_small).astype(int)\n",
    "\n",
    "\n",
    "index_returns = df_price['^OMXSPI'].pct_change()\n",
    "proxy_a_df['Market_Return_Increase'] = (index_returns > 0).astype(int)\n",
    "proxy_a_df['Market_Return_Decrease'] = (index_returns < 0).astype(int)\n",
    "\n",
    "proxy_a_df.to_excel(f'{path}/raw_data/main/proxy_a.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proxy B:\n",
    "\n",
    "Daily raw stock returns with absolute values exceeding 3 and 4 standard deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_2013 = yf.download(tickers_list, start=\"2013-03-06\") #Downloading prior year's prices to calculate standard deviations ovet the las 250 trading days\n",
    "price_2013.to_csv(f'{path}/raw_data/main/price_2013.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "threshold_3_std = 3\n",
    "threshold_4_std = 4\n",
    "window_size = 250 # Number of trading days for calculating the rolling standard deviation\n",
    "df_price_2013 = pd.read_excel(f\"{path}/raw_data/main/price_2013.xlsx\")\n",
    "\n",
    "proxy_b_df = pd.DataFrame(df_price['Date'].copy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df_price_2013.columns[1:-1]:  # Exclude the 'Date' and '^OMXSPI' columns\n",
    "    stock_returns = df_price_2013[column].pct_change()\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "            'Date': df_price_2013['Date'],\n",
    "            'Stock_Returns': stock_returns\n",
    "        })\n",
    "\n",
    "\n",
    "    rolling_std = stock_returns.rolling(window=window_size).std()\n",
    "\n",
    "\n",
    "    result_df[f'{column}_Increase_3std'] = (stock_returns > threshold_3_std * rolling_std).astype(int)\n",
    "    result_df[f'{column}_Decrease_3std'] = (stock_returns < - threshold_3_std * rolling_std).astype(int)\n",
    "    result_df[f'{column}_Increase_4std'] = (stock_returns > threshold_4_std * rolling_std).astype(int)\n",
    "    result_df[f'{column}_Decrease_4std'] = (stock_returns < - threshold_4_std * rolling_std).astype(int)\n",
    "\n",
    "\n",
    "result_df = result_df[result_df['Date']>='2014-03-06']\n",
    "result_df.drop(columns=['Stock_Returns'],inplace=True)\n",
    "proxy_b_df=pd.merge(proxy_b_df,result_df,left_on='Date', right_on='Date', how='left')\n",
    "proxy_b_df.head()\n",
    "\n",
    "index_returns = df_price['^OMXSPI'].pct_change()\n",
    "proxy_b_df['Market_Return_Increase'] = (index_returns > 0).astype(int)\n",
    "proxy_b_df['Market_Return_Decrease'] = (index_returns < 0).astype(int)\n",
    "\n",
    "proxy_b_df.to_excel(f'{path}/raw_data/main/proxy_b.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Proxy C\n",
    "\n",
    "Daily abnormal stock returns with absolute values exceeding 8% and 10% using Market Model Adjusted Returns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The risk-free interest rate corresponds to the 1-month Swedish Treasury Bills. It has been obtained from [Sveriges Riskbank]('https://www.riksbank.se/en-gb/statistics/interest-rates-and-exchange-rates/search-interest-rates-and-exchange-rates/?s=g6-SETB1MBENCHC&fs=2#riksbank-seriesform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_8_percent_large = 0.08\n",
    "threshold_10_percent_large = 0.10\n",
    "\n",
    "threshold_10_percent_mid = 0.10\n",
    "threshold_12_percent_mid = 0.12\n",
    "\n",
    "threshold_13_percent_small = 0.13\n",
    "threshold_15_percent_small =  0.15\n",
    "\n",
    "window_size = 250  # Number of trading days for estimating beta\n",
    "\n",
    "\n",
    "risk_free_rate_df= pd.read_excel(f\"{path}/raw_data/main/risk_free.xlsx\")\n",
    "risk_free_rate_df['Swedish Treasury Bills (SE TB 1 Month)'].fillna(method='ffill', inplace=True)\n",
    "risk_free_rate_df['Swedish Treasury Bills (SE TB 1 Month)']= (1 + risk_free_rate_df['Swedish Treasury Bills (SE TB 1 Month)']) ** (1/250) - 1\n",
    "\n",
    "proxy_c_df = pd.DataFrame(df_price['Date'].copy())\n",
    "\n",
    "\n",
    "for column in l_caps_list:  # Exclude the 'Date' and '^OMXSPI' column\n",
    "\n",
    "    stock_returns = df_price_2013[column].pct_change()\n",
    "\n",
    "    # Market returns (e.g., using OMXSPI as a proxy for the market)\n",
    "    market_returns = df_price_2013['^OMXSPI'].pct_change()\n",
    "\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "    'Date': df_price_2013['Date'],\n",
    "    'Stock_Returns': stock_returns,\n",
    "    'Market_Returns': market_returns\n",
    "})\n",
    "    # Beta is calculated as the covariance of the stock's returns with the market returns divided by the variance of the market returns over the preceding 250 trading days.\n",
    "    result_df['beta'] = result_df['Stock_Returns'].rolling(window=window_size).cov(result_df['Market_Returns']).div(result_df['Market_Returns'].rolling(window=window_size).var())\n",
    "    result_df = pd.merge(result_df,risk_free_rate_df, left_on='Date', right_on='Date', how='left')\n",
    "\n",
    "\n",
    "    # Ri = Rf + beta * (Rm-Rf) + ei --> Ri - [Rf + beta * (Rm - Rf)]\n",
    "    result_df['MMAR'] = result_df['Swedish Treasury Bills (SE TB 1 Month)']+ result_df['beta'] * (result_df['Market_Returns']- result_df['Swedish Treasury Bills (SE TB 1 Month)'])\n",
    "\n",
    "    result_df[f'{column}_ARs'] = result_df['Stock_Returns'] - result_df['MMAR']\n",
    "\n",
    "\n",
    "    result_df.drop(columns=['Stock_Returns','Market_Returns','beta','Swedish Treasury Bills (SE TB 1 Month)','MMAR'],inplace=True)\n",
    "\n",
    "    proxy_c_df = pd.merge(proxy_c_df,result_df, left_on='Date',right_on='Date',how='left')\n",
    "\n",
    "    proxy_c_df[f'{column}_Increase_small_thres'] = (proxy_c_df[f'{column}_ARs'] > threshold_8_percent_large).astype(int)\n",
    "    proxy_c_df[f'{column}_Decrease_small_thres'] = (proxy_c_df[f'{column}_ARs'] < -threshold_8_percent_large).astype(int)\n",
    "    proxy_c_df[f'{column}_Increase_large_thres'] = (proxy_c_df[f'{column}_ARs'] > threshold_10_percent_large).astype(int)\n",
    "    proxy_c_df[f'{column}_Decrease_large_thres'] = (proxy_c_df[f'{column}_ARs'] < - threshold_10_percent_large).astype(int)\n",
    "    proxy_c_df.drop(columns=[f'{column}_ARs'],inplace=True)\n",
    "\n",
    "for column in m_caps_list:  # Exclude the 'Date' and '^OMXSPI' column\n",
    "\n",
    "    stock_returns = df_price_2013[column].pct_change()\n",
    "\n",
    "    # Market returns (e.g., using OMXSPI as a proxy for the market)\n",
    "    market_returns = df_price_2013['^OMXSPI'].pct_change()\n",
    "\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "    'Date': df_price_2013['Date'],\n",
    "    'Stock_Returns': stock_returns,\n",
    "    'Market_Returns': market_returns\n",
    "})\n",
    "    # Beta is calculated as the covariance of the stock's returns with the market returns divided by the variance of the market returns over the preceding 250 trading days.\n",
    "    result_df['beta'] = result_df['Stock_Returns'].rolling(window=window_size).cov(result_df['Market_Returns']).div(result_df['Market_Returns'].rolling(window=window_size).var())\n",
    "    result_df = pd.merge(result_df,risk_free_rate_df, left_on='Date', right_on='Date', how='left')\n",
    "\n",
    "\n",
    "    # Ri = Rf + beta * (Rm-Rf) + ei --> Ri - [Rf + beta * (Rm - Rf)]\n",
    "    result_df['MMAR'] = result_df['Swedish Treasury Bills (SE TB 1 Month)']+ result_df['beta'] * (result_df['Market_Returns']- result_df['Swedish Treasury Bills (SE TB 1 Month)'])\n",
    "\n",
    "    result_df[f'{column}_ARs'] = result_df['Stock_Returns'] - result_df['MMAR']\n",
    "\n",
    "\n",
    "    result_df.drop(columns=['Stock_Returns','Market_Returns','beta','Swedish Treasury Bills (SE TB 1 Month)','MMAR'],inplace=True)\n",
    "\n",
    "    proxy_c_df = pd.merge(proxy_c_df,result_df, left_on='Date',right_on='Date',how='left')\n",
    "\n",
    "    proxy_c_df[f'{column}_Increase_small_thres'] = (proxy_c_df[f'{column}_ARs'] > threshold_10_percent_mid).astype(int)\n",
    "    proxy_c_df[f'{column}_Decrease_small_thres'] = (proxy_c_df[f'{column}_ARs'] < -threshold_10_percent_mid).astype(int)\n",
    "    proxy_c_df[f'{column}_Increase_large_thres'] = (proxy_c_df[f'{column}_ARs'] > threshold_15_percent_small).astype(int)\n",
    "    proxy_c_df[f'{column}_Decrease_large_thres'] = (proxy_c_df[f'{column}_ARs'] < - threshold_15_percent_small).astype(int)\n",
    "    proxy_c_df.drop(columns=[f'{column}_ARs'],inplace=True)\n",
    "\n",
    "for column in s_caps_list:  # Exclude the 'Date' and '^OMXSPI' column\n",
    "\n",
    "    stock_returns = df_price_2013[column].pct_change()\n",
    "\n",
    "    # Market returns (e.g., using OMXSPI as a proxy for the market)\n",
    "    market_returns = df_price_2013['^OMXSPI'].pct_change()\n",
    "\n",
    "\n",
    "    result_df = pd.DataFrame({\n",
    "    'Date': df_price_2013['Date'],\n",
    "    'Stock_Returns': stock_returns,\n",
    "    'Market_Returns': market_returns\n",
    "})\n",
    "    # Beta is calculated as the covariance of the stock's returns with the market returns divided by the variance of the market returns over the preceding 250 trading days.\n",
    "    result_df['beta'] = result_df['Stock_Returns'].rolling(window=window_size).cov(result_df['Market_Returns']).div(result_df['Market_Returns'].rolling(window=window_size).var())\n",
    "    result_df = pd.merge(result_df,risk_free_rate_df, left_on='Date', right_on='Date', how='left')\n",
    "\n",
    "\n",
    "    # Ri = Rf + beta * (Rm-Rf) + ei --> Ri - [Rf + beta * (Rm - Rf)]\n",
    "    result_df['MMAR'] = result_df['Swedish Treasury Bills (SE TB 1 Month)']+ result_df['beta'] * (result_df['Market_Returns']- result_df['Swedish Treasury Bills (SE TB 1 Month)'])\n",
    "\n",
    "    result_df[f'{column}_ARs'] = result_df['Stock_Returns'] - result_df['MMAR']\n",
    "\n",
    "\n",
    "    result_df.drop(columns=['Stock_Returns','Market_Returns','beta','Swedish Treasury Bills (SE TB 1 Month)','MMAR'],inplace=True)\n",
    "\n",
    "    proxy_c_df = pd.merge(proxy_c_df,result_df, left_on='Date',right_on='Date',how='left')\n",
    "\n",
    "    proxy_c_df[f'{column}_Increase_small_thres'] = (proxy_c_df[f'{column}_ARs'] > threshold_13_percent_small).astype(int)\n",
    "    proxy_c_df[f'{column}_Decrease_small_thres'] = (proxy_c_df[f'{column}_ARs'] < -threshold_13_percent_small).astype(int)\n",
    "    proxy_c_df[f'{column}_Increase_large_thres'] = (proxy_c_df[f'{column}_ARs'] > threshold_15_percent_small).astype(int)\n",
    "    proxy_c_df[f'{column}_Decrease_large_thres'] = (proxy_c_df[f'{column}_ARs'] < - threshold_15_percent_small).astype(int)\n",
    "    proxy_c_df.drop(columns=[f'{column}_ARs'],inplace=True)\n",
    "\n",
    "index_returns = df_price['^OMXSPI'].pct_change()\n",
    "proxy_c_df['Market_Return_Increase'] = (index_returns > 0).astype(int)\n",
    "proxy_c_df['Market_Return_Decrease'] = (index_returns < 0).astype(int)\n",
    "\n",
    "proxy_c_df.to_excel(f\"{path}/raw_data/main/proxy_c.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "empirical",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
